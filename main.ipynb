{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d05ae81-3e86-47eb-8580-58aae9c452df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchmetrics\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94f820-629a-47f2-916a-6018191946e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.0/29.0 [00:00<00:00, 9.83kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208k/208k [00:00<00:00, 296kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 426k/426k [00:01<00:00, 400kB/s]\n",
      "Downloading:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 189M/1.25G [07:29<52:32, 362kB/s]"
     ]
    }
   ],
   "source": [
    "base_model_name = \"bert-large-cased\"\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "def tokenize_function(examples, max_length):\n",
    "    return tokenizer(examples, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b1691f-1066-45f7-aa88-db6807708cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "â”œâ”€BertModel: 1-1                         --\n",
      "|    â””â”€BertEmbeddings: 2-1               --\n",
      "|    |    â””â”€Embedding: 3-1               22,268,928\n",
      "|    |    â””â”€Embedding: 3-2               393,216\n",
      "|    |    â””â”€Embedding: 3-3               1,536\n",
      "|    |    â””â”€LayerNorm: 3-4               1,536\n",
      "|    |    â””â”€Dropout: 3-5                 --\n",
      "|    â””â”€BertEncoder: 2-2                  --\n",
      "|    |    â””â”€ModuleList: 3-6              85,054,464\n",
      "|    â””â”€BertPooler: 2-3                   --\n",
      "|    |    â””â”€Linear: 3-7                  590,592\n",
      "|    |    â””â”€Tanh: 3-8                    --\n",
      "â”œâ”€Dropout: 1-2                           --\n",
      "â”œâ”€Linear: 1-3                            1,538\n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc4bdff-a7c0-4683-ae61-12cd080d43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df[df['location'].notnull()]\n",
    "\n",
    "# Remove links\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['len'] = df['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48609fe2-76ad-408c-b2c2-a7455c3a2fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was fire  freash meat  '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = r'It was fire :), freash meat ðŸ”¥ðŸ”¥ www.site.com'\n",
    "text_processor = utils.TextPreprocessor(\n",
    "    # pkl='data/emoticons.pkl'\n",
    ")\n",
    "text_processor(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bd3f28-9d86-4172-94ae-e70e00821448",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenize_function(df['text'].tolist(), df['len'].max())\n",
    "Y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697bf509-70f1-4602-926c-5b3e25dc7c14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Classifier on BERT's embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06de0db8-35ce-4add-9511-422465d462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'd': [64, 32],\n",
    "    'dropout': 0.5,\n",
    "    'n_components': 384,\n",
    "    'batch_size': 1024,\n",
    "    'tuned_model_name': 'BERT Tune ',\n",
    "}\n",
    "\n",
    "if config['tuned_model_name'] is not None:\n",
    "    state_dict = torch.load(f'Models/W/{config[\"tuned_model_name\"]}.torch')\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f515e-d8f4-4cd8-b252-0ab15858051b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4d2540d-4487-465f-aedf-768ecdf1a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "batch_size = 512\n",
    "\n",
    "num_batches = len(df)//batch_size\n",
    "if len(df)%batch_size != 0:\n",
    "    num_batches+= 1\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in range(num_batches):\n",
    "        inputs = {\n",
    "            k: v[batch*batch_size:(batch+1)*batch_size].to(device) \n",
    "                  for k, v in x.items()\n",
    "        }\n",
    "        \n",
    "        outputs = model.bert(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            token_type_ids=inputs['token_type_ids'],\n",
    "        )\n",
    "        \n",
    "        X.append(outputs.pooler_output.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c296cbfe-13d9-4def-9082-1446dea5d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "X = torch.cat(X)\n",
    "Y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "757246d8-f777-4b67-be8a-9f383a1aa977",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.1, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ecc4ecc-206c-41cc-9fc9-9f58c68dfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = utils.EmbeddingDataset(Xtrain, Ytrain)\n",
    "val_dataset = utils.EmbeddingDataset(Xval, Yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78469c45-abe8-4692-9378-f3c875ad1719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edb803e3-aed6-46b2-8b40-e314ad4af74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(name):    \n",
    "    print(name)\n",
    "\n",
    "    checkpoint = torch.load(f'Models/W/{name}.torch')\n",
    "    classification_model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    val_pred, val_true = trainer.val(val_dataloader)\n",
    "    val_pred = val_pred.softmax(1)\n",
    "    print('AUC:', auc(val_pred, val_true))\n",
    "    print('ACC:', acc(val_pred, val_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2088bf2-3f6c-48fa-b9c6-e2591794129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "n_components = config['n_components']\n",
    "if n_components is not None:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(Xtrain)\n",
    "    \n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=config['batch_size'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'])\n",
    "\n",
    "classification_model = utils.ClassifierModel(\n",
    "    input_dim=n_components if n_components is not None else train_dataset.shape()[1], \n",
    "    callable_=None if n_components is None else pca.transform,\n",
    "    output_dim=2,\n",
    "    **config,\n",
    ").to(device)\n",
    "\n",
    "trainer = utils.Trainer(\n",
    "    model=classification_model,\n",
    "    metric=torchmetrics.AUROC(num_classes=2),\n",
    "    loss_fn=nn.CrossEntropyLoss(reduce=True),\n",
    "    optimizer=torch.optim.AdamW(classification_model.parameters(), lr=3e-4),\n",
    ")\n",
    "\n",
    "acc = torchmetrics.Accuracy(num_classes=2)\n",
    "auc = torchmetrics.AUROC(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d08c0560-be6b-4176-abf4-899cdd7181c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'BERT {4} embeddings + {0} + {1} + {2} + {3} '.format(\n",
    "    f\"{config['n_components']} pca\", \n",
    "    f\"{config['d']} d\",\n",
    "    f\"{config['dropout']} dropout\",\n",
    "    f\"{config['batch_size']} batchsize\",\n",
    "    f\"tuned\" if config['tuned_model_name'] is not None else \"\",\n",
    ")\n",
    "board_name = name + datetime.datetime.now().strftime(\"%Y.%m.%d - %H-%M-%S\")\n",
    "\n",
    "log_dir = f\"logs/fit/{board_name}\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04ebe4b1-e35c-48b7-8bf3-ab643c11b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait = 0\n",
    "    patience = 150\n",
    "\n",
    "    epoch = 0\n",
    "    best_loss = -np.inf\n",
    "    while wait < patience:\n",
    "        train_loss = trainer.train(train_dataloader, epoch)\n",
    "\n",
    "        val_pred, val_true = trainer.val(val_dataloader)\n",
    "        val_pred = val_pred.softmax(1)\n",
    "        metrics = {\n",
    "            'AUC': auc(val_pred, val_true),\n",
    "            'ACC': acc(val_pred, val_true),\n",
    "        }\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('AUC/train', trainer.metric.compute(), epoch)\n",
    "        writer.add_scalar('AUC/val', metrics['AUC'], epoch)\n",
    "        writer.add_scalar('ACC/val', metrics['ACC'], epoch)\n",
    "\n",
    "\n",
    "        wait+=1\n",
    "        epoch+=1\n",
    "        if metrics['AUC'] > best_loss:\n",
    "            checkpoint = trainer.checkpoint()\n",
    "            torch.save(checkpoint, f'Models/W/{name}.torch')\n",
    "            best_loss = metrics['AUC']\n",
    "            wait = 0\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2a234-ac22-462d-aff3-3847cd60d59c",
   "metadata": {},
   "source": [
    "### resluts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f7a868f-274f-49e5-bece-23a09ee8cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT tuned embeddings + None pca + [128, 64] d + 0.5 dropout + 1024 batchsize \n",
      "AUC: tensor(0.8849)\n",
      "ACC: tensor(0.8281)\n"
     ]
    }
   ],
   "source": [
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c689e9b5-6da7-432f-a37b-a8e5e6405fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT tuned embeddings + 384 pca + [64, 32] d + 0.5 dropout + 1024 batchsize \n",
      "AUC: tensor(0.8805)\n",
      "ACC: tensor(0.8294)\n"
     ]
    }
   ],
   "source": [
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75fd6b1b-3c8a-4be4-b164-3ecd25128902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings + 384 pca + [64, 32] d + 0.5 dropout + 1024 batchsize \n",
      "AUC: tensor(0.8397)\n",
      "ACC: tensor(0.7887)\n"
     ]
    }
   ],
   "source": [
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a69eda8-0829-4331-924f-75df99fe5536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings + 256 pca + [128, 64] d + 0.15 dropout \n",
      "AUC: tensor(0.8247)\n",
      "ACC: tensor(0.7782)\n"
     ]
    }
   ],
   "source": [
    "# With links in text\n",
    "# 2048 batch\n",
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73263e79-cede-484a-af6f-8319737841da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings + 512 pca + [128, 64] d \n",
      "AUC: tensor(0.8231)\n",
      "ACC: tensor(0.7769)\n"
     ]
    }
   ],
   "source": [
    "# With links in text\n",
    "# 2048 batch\n",
    "# 0.5 dropout\n",
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f91ad013-2077-407b-8676-473ada045e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings + None pca + [128, 64] d\n",
      "AUC: tensor(0.8180)\n",
      "ACC: tensor(0.7677)\n"
     ]
    }
   ],
   "source": [
    "# With links in text\n",
    "# 2048 batch\n",
    "# 0.5 dropout\n",
    "validate(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba5c07-edcc-4f99-8b15-07a5789f76eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3945bf1-001d-4cdb-9847-b3bfd0b5ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # batchsize is acum_iter*batch_size\n",
    "    batch_size = 96 # 128->96 due preproccesing that increase max len\n",
    "    accum_iter = 4\n",
    "    preproc = True\n",
    "    rand = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d63303-e27b-4a6c-8c47-dbd9a1c1cc1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c8f74f-2c38-40e3-b6ce-0c7afb8d5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.preproc:\n",
    "    new_df = df.copy()\n",
    "    new_df['text'] = new_df['text'].apply(lambda x: text_processor(x))\n",
    "    new_df['len'] = new_df['text'].apply(lambda x: len(x))\n",
    "    \n",
    "    x = tokenize_function(new_df['text'].tolist(), 260)\n",
    "    Y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d78487-ed46-423a-a133-8e9dd04bf2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDXtrain, IDXval, Ytrain, Yval = train_test_split(np.arange(len(Y)), Y, test_size=0.1, random_state=69)\n",
    "\n",
    "Xtrain = {k: v[IDXtrain] for k, v in x.items()}\n",
    "Xval = {k: v[IDXval] for k, v in x.items()}\n",
    "\n",
    "train_dataset = utils.NLPDataset(Xtrain, Ytrain, rand=config.rand)\n",
    "val_dataset = utils.NLPDataset(Xval, Yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c60d8f-8077-42a8-bf74-444d736545c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45d24b0-b6a3-468d-b4b9-774326775845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    progress_bar = tqdm(range(len(train_dataloader)))\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        batch = [item.to(device) for item in batch]\n",
    "        labels, input_ids, attention_mask, token_type_ids = batch\n",
    "\n",
    "        outputs = model(\n",
    "            labels=labels,\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        if ((batch_idx + 1) % config.accum_iter == 0) or (batch_idx + 1 == len(train_dataloader)):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        _x, _y = outputs.logits.cpu().softmax(1), labels.cpu()\n",
    "        train_acc(_x, _y)\n",
    "        train_auc(_x, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2a4f39-0a17-4c16-90c3-3751fbd8cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    val_pred, val_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = [item.to(device) for item in batch]\n",
    "            labels, input_ids, attention_mask, token_type_ids = batch\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "            )\n",
    "\n",
    "            val_true.append(labels.cpu())\n",
    "            val_pred.append(outputs.logits.cpu())\n",
    "            \n",
    "    val_pred = torch.cat(val_pred)\n",
    "    val_true = torch.cat(val_true)\n",
    "    return val_pred, val_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae2685d8-43b9-4f84-9068-44e4c7529f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(name): \n",
    "    print(name)\n",
    "\n",
    "    state_dict = torch.load(f'Models/W/{name}.torch')\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    val_pred, val_true = evaluate()\n",
    "    val_pred = val_pred.softmax(1)\n",
    "    print('AUC:', auc(val_pred, val_true))\n",
    "    print('ACC:', acc(val_pred, val_true))\n",
    "    print('F1:', f1(val_pred, val_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a06a67-8634-47c7-a8ff-833fca455ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=config.batch_size, pin_memory=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "acc = torchmetrics.Accuracy(num_classes=2)\n",
    "auc = torchmetrics.AUROC(num_classes=2)\n",
    "f1 = torchmetrics.F1Score(num_classes=2)\n",
    "\n",
    "train_acc = torchmetrics.Accuracy(num_classes=2)\n",
    "train_auc = torchmetrics.AUROC(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908f7c9c-f7da-42e4-8569-9009c6ea7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'BERT Tune {0} {1}'.format(\n",
    "    'rand' if config.rand else '',\n",
    "    'preproc' if config.preproc else '',\n",
    ")\n",
    "\n",
    "board_name = name + datetime.datetime.now().strftime(\"%Y.%m.%d - %H-%M-%S\")\n",
    "\n",
    "log_dir = f\"logs/fit/{board_name}\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f288701-0f16-45df-b176-41358d959835",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2510cd72-9646-4b16-ad89-3c82e51e0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [13:59<00:00, 11.66s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [14:51<00:00, 12.38s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [13:29<00:00, 11.24s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [13:14<00:00, 11.04s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [11:51<00:00,  9.88s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [13:22<00:00, 11.15s/it]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    wait = 0\n",
    "    patience = 5\n",
    "\n",
    "    epoch = 0\n",
    "    best_loss = -np.inf\n",
    "    while wait < patience:\n",
    "        train_epoch()\n",
    "\n",
    "        val_pred, val_true = evaluate()\n",
    "        val_pred = val_pred.softmax(1)\n",
    "        metrics = {\n",
    "            'AUC': auc(val_pred, val_true),\n",
    "            'ACC': acc(val_pred, val_true),\n",
    "            'F1': f1(val_pred, val_true),\n",
    "        }\n",
    "\n",
    "        writer.add_scalar('ACC/train', train_acc.compute(), epoch)\n",
    "        writer.add_scalar('AUC/train', train_auc.compute(), epoch)\n",
    "        writer.add_scalar('AUC/val', metrics['AUC'], epoch)\n",
    "        writer.add_scalar('ACC/val', metrics['ACC'], epoch)\n",
    "        \n",
    "        acc.reset()\n",
    "        auc.reset()\n",
    "        train_acc.reset()\n",
    "        train_auc.reset()\n",
    "        \n",
    "        wait+=1\n",
    "        epoch+=1\n",
    "        if metrics['AUC'] > best_loss:\n",
    "            torch.save(model.state_dict(), f'Models/W/{name}.torch')\n",
    "            best_loss = metrics['AUC']\n",
    "            wait = 0\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858510d3-5bfa-4122-9239-b3e677a7c4d0",
   "metadata": {},
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e3c2ef-fc56-4470-9180-5d0fa6921b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Tune rand preproc\n",
      "AUC: tensor(0.8695)\n",
      "ACC: tensor(0.8018)\n",
      "F1: tensor(0.8018)\n"
     ]
    }
   ],
   "source": [
    "# cringe\n",
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "230b8238-4c80-4f50-a446-edf2425a555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Tune rand\n",
      "AUC: tensor(0.8831)\n",
      "ACC: tensor(0.8150)\n",
      "F1: tensor(0.8150)\n"
     ]
    }
   ],
   "source": [
    "validate(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e19f136f-15e2-41fb-a08b-af99d32f3ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Tune \n",
      "AUC: tensor(0.8837)\n",
      "ACC: tensor(0.8228)\n",
      "F1: tensor(0.8228)\n"
     ]
    }
   ],
   "source": [
    "validate(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9852f0-7ec0-4e59-837c-a3d6b9959df1",
   "metadata": {},
   "source": [
    "# End to end transformer\n",
    "\n",
    "w.i.p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee4ea655-dbdc-4dde-9810-88a604bac328",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
